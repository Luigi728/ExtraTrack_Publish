{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ad0ab9-3382-4f75-b98a-ceeabae6e0d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LATITUDE_FORMATTER, LONGITUDE_FORMATTER\n",
    "import cftime\n",
    "import datetime\n",
    "from datetime import date\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy\n",
    "import pandas\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e3e8bb-5b7b-4f61-ae85-5e9d39fc21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directories\n",
    "Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Publish/Storm_Data_Raw/'\n",
    "Output_Diri = '/glade/u/home/whimkao//ExtraTrack/ExtraTrack_Publish/Storm_Tracking/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf58d309-5e19-4be0-b07c-8fa56d34f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open File\n",
    "def Create_DF(File):\n",
    "    Data = open(File, 'r')\n",
    "    Rows = []\n",
    "#\n",
    "# Organize Data From Raw Dataset\n",
    "    for Line in Data:\n",
    "        Rows.append(Line.strip())\n",
    "    Storm_Code, Storm_List_Orig = [], []\n",
    "    for i in range(len(Rows)):\n",
    "        if Rows[i][0:5] == 'start':\n",
    "            Code = Rows[i][41:45]\n",
    "            Storm_List_Orig.append(Code)\n",
    "        else:\n",
    "            Storm_Code.append(Code)\n",
    "    Array = numpy.zeros((13, len(Rows)-len(Storm_List_Orig)))\n",
    "    Time = []\n",
    "    k = -1\n",
    "    for i in range(len(Rows)):\n",
    "        if Rows[i][0:5] == 'start':\n",
    "            k += 1\n",
    "        else:\n",
    "            l = len(Rows[i]) - 100\n",
    "            Array[0][i-k-1] = float(Rows[i][0:6+l])\n",
    "            Array[1][i-k-1] = float(Rows[i][8+l:14+l])\n",
    "            Array[2][i-k-1] = float(Rows[i][17+l:24+l])\n",
    "            Array[3][i-k-1] = float(Rows[i][26+l:31+l])\n",
    "            Array[4][i-k-1] = float(Rows[i][34+l:41+l])\n",
    "            Array[5][i-k-1] = float(Rows[i][44+l:51+l])\n",
    "            Array[6][i-k-1] = float(Rows[i][54+l:61+l])\n",
    "            Array[7][i-k-1] = float(Rows[i][64+l:71+l])\n",
    "            Array[8][i-k-1] = float(Rows[i][74+l:81+l])\n",
    "            Time.append(datetime.datetime(year=int(Rows[i][84+l:88+l]), month=int(Rows[i][90+l:92+l]), \\\n",
    "            day=int(Rows[i][94+l:96+l]), hour=int(Rows[i][98+l:100+l])))\n",
    "#\n",
    "# Create DataFrame to Store Data\n",
    "    DF_All = pandas.DataFrame({\"Orig Code\": Storm_Code, \"Lon\": Array[0], \"Lat\": Array[1], \"SLP(hPa)\": Array[2], \\\n",
    "    \"Winds(m/s)\": Array[3], \"Dist(m)\": Array[4], \"Angle\": Array[5], \"B\": Array[6], \"VLT\": Array[7], \"VUT\": Array[8], \\\n",
    "    \"Orig Time(Z)\": Time})\n",
    "#\n",
    "# Remove Data Points Missing Phase Space Parameter Values (-999.0)\n",
    "    DF = DF_All[(DF_All[\"B\"] > -728) & (DF_All[\"VLT\"] > -728) & (DF_All[\"VUT\"] > -728)].reset_index()\n",
    "    return (DF, Storm_List_Orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6da6f39-c4e1-4979-a6f0-0839f1bb1ad5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine The Three Datasets Into One DataFrame of 90 or 93 Years For Each Scenario\n",
    "def Combine_DF(DF_A, DF_B, DF_C, Orig_List_A, Orig_List_B, Orig_List_C, Model):\n",
    "# Change Date For Simplicity of Analysis\n",
    "# Control Assigned to Years in the 20th Century\n",
    "# Each Year Within the Century are Independent\n",
    "    if Model == \"Control\":\n",
    "        Year_Start = 1900\n",
    "# RCP4.5 Assigned to Years in the 21st Century\n",
    "    elif Model == \"RCP45\":\n",
    "        Year_Start = 2000\n",
    "# RCP8.5 Assigned to Years in the 22nd Century\n",
    "    elif Model == \"RCP85\":\n",
    "        Year_Start = 2100\n",
    "# Create Empty Lists\n",
    "    Origi_List_A, Origi_List_B, Origi_List_C = [], [], []\n",
    "    New_List_A, New_List_B, New_List_C = [], [], []\n",
    "    New_Time, New_Code, ABC = [], [], []\n",
    "    Orig_Combine, New_Combine = [], []\n",
    "# Dataset A\n",
    "    Year = Year_Start\n",
    "    Orig_Year = DF_A[\"Orig Time(Z)\"][0].year\n",
    "    Year_Diff_A = Year - Orig_Year\n",
    "    Count = 0\n",
    "    for k in range(len(Orig_List_A)):\n",
    "        try:\n",
    "            Code, Year, Count = Update_Code(DF_A, Orig_List_A[k], Year_Diff_A, Year, Count)\n",
    "            Origi_List_A.append(Orig_List_A[k])\n",
    "            New_List_A.append(Code)\n",
    "        except:\n",
    "            Except = 0\n",
    "# Dataset B\n",
    "    Year += 1\n",
    "    Orig_Year = DF_B[\"Orig Time(Z)\"][0].year\n",
    "    Year_Diff_B = Year - Orig_Year\n",
    "    Count = 0\n",
    "    for k in range(len(Orig_List_B)):\n",
    "        try:\n",
    "            Code, Year, Count = Update_Code(DF_B, Orig_List_B[k], Year_Diff_B, Year, Count)\n",
    "            Origi_List_B.append(Orig_List_B[k])\n",
    "            New_List_B.append(Code)\n",
    "        except:\n",
    "            Except = 0\n",
    "# Dataset C\n",
    "    Year += 1\n",
    "    Orig_Year = DF_C[\"Orig Time(Z)\"][0].year\n",
    "    Year_Diff_C = Year - Orig_Year\n",
    "    Count = 0\n",
    "    for k in range(len(Orig_List_C)):\n",
    "        try:\n",
    "            Code, Year, Count = Update_Code(DF_C, Orig_List_C[k], Year_Diff_C, Year, Count)\n",
    "            Origi_List_C.append(Orig_List_C[k])\n",
    "            New_List_C.append(Code)\n",
    "        except:\n",
    "            Except = 0\n",
    "#\n",
    "# Combine Into New Time and Codes List\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine = Combine_Lists(DF_A, Origi_List_A, New_List_A, Year_Diff_A, \\\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine, \"A\")\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine = Combine_Lists(DF_B, Origi_List_B, New_List_B, Year_Diff_B, \\\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine, \"B\")\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine = Combine_Lists(DF_C, Origi_List_C, New_List_C, Year_Diff_C, \\\n",
    "    New_Code, New_Time, ABC, Orig_Combine, New_Combine, \"C\")\n",
    "#\n",
    "# Concatenate Other Variables\n",
    "    Vars = [\"Lon\", \"Lat\", \"SLP(hPa)\", \"Winds(m/s)\", \"Dist(m)\", \"Angle\", \"B\", \"VLT\", \"VUT\"]\n",
    "    Total_Length = len(New_Code)\n",
    "    Array = numpy.zeros((9,Total_Length))\n",
    "    for n in range(len(Vars)):\n",
    "        List = []\n",
    "        for k in range(len(DF_A)):\n",
    "            List.append(DF_A[Vars[n]][k])\n",
    "        for k in range(len(DF_B)):\n",
    "            List.append(DF_B[Vars[n]][k])\n",
    "        for k in range(len(DF_C)):\n",
    "            List.append(DF_C[Vars[n]][k])\n",
    "        Array[n] = List\n",
    "#\n",
    "# Create DataFrame to Store Data\n",
    "    DF_Combine = pandas.DataFrame({\"Code\": New_Code, \"Lon\": Array[0], \"Lat\": Array[1], \"SLP(hPa)\": Array[2], \\\n",
    "    \"Winds(m/s)\": Array[3], \"B\": Array[6], \"VLT\": Array[7], \"VUT\": Array[8], \"Time(Z)\": New_Time})\n",
    "    Codes_DF = pandas.DataFrame({\"ABC\": ABC, \"Orig Code\": Orig_Combine, \"New Code\": New_Combine})\n",
    "    Year_Diffs = numpy.array([Year_Diff_A, Year_Diff_B, Year_Diff_C])\n",
    "    return (DF_Combine, Codes_DF, Year_Diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3425f5-0a27-4e01-bebb-76948faaffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Storm Code to Contain Year and Storm Number\n",
    "def Update_Code(DF, Orig_Code, Year_Diff_A, Year, Count):\n",
    "    DF_Storm = DF[DF[\"Orig Code\"] == Orig_Code].reset_index()\n",
    "    Orig_Year = DF_Storm[\"Orig Time(Z)\"][0].year\n",
    "    Time_Year = Orig_Year + Year_Diff_A\n",
    "    if Time_Year == Year:\n",
    "        Count += 1\n",
    "    else:\n",
    "        Year += 1\n",
    "        Count = 1\n",
    "    if Count < 10:\n",
    "        Code = \"TC\"+str(Year)+\"0\"+str(Count)\n",
    "    else:\n",
    "        Code = \"TC\"+str(Year)+str(Count)\n",
    "    return (Code, Year, Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0685dd59-c4f4-420a-97b3-bf89262d0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Lists\n",
    "def Combine_Lists(DF, Orig_List, New_List, Year_Diff, New_Code, New_Time, ABC, Orig_Combine, New_Combine, Y):\n",
    "    for i in range(len(DF)):\n",
    "        for l in range(len(Orig_List)):\n",
    "# Update Storm Code\n",
    "            if DF[\"Orig Code\"][i] == Orig_List[l]:\n",
    "                New_Code.append(New_List[l])\n",
    "# Update Year\n",
    "                Orig_Time = DF[\"Orig Time(Z)\"][i]\n",
    "                New_Time.append(Update_Year(Orig_Time, Year_Diff))\n",
    "    for m in range(len(Orig_List)):\n",
    "        ABC.append(Y)\n",
    "        Orig_Combine.append(Orig_List[m])\n",
    "        New_Combine.append(New_List[m])\n",
    "    return (New_Code, New_Time, ABC, Orig_Combine, New_Combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd009122-8d02-4693-a3bc-ce6c903c1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Year of Data\n",
    "def Update_Year(Orig_Time, Year_Diff):\n",
    "    Year_Update = Orig_Time.year + Year_Diff\n",
    "# Febuary 29 Issues\n",
    "    if Orig_Time.month == 2 and Orig_Time.day == 29:\n",
    "        New_Time = Orig_Time.replace(year=Year_Update, day=28)\n",
    "    else:\n",
    "        New_Time = Orig_Time.replace(year=Year_Update)\n",
    "    return (New_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3cca02-d0c1-48d5-b44d-ecce1a28fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Name List File\n",
    "def Open_Name_List(File):\n",
    "    Name_File = pandas.read_csv(File)\n",
    "    Headings = list(Name_File.columns)\n",
    "    Name_List = []\n",
    "    for i in range(len(Headings)):\n",
    "        for j in range(len(Name_File)):\n",
    "            Name_List.append(Name_File[Headings[i]][j])\n",
    "    return (Name_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f19c405-00f6-461c-b1f7-648700f534ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Names to Each Cyclone Code\n",
    "def Assign_Name(Name_List, Codes, DF):\n",
    "    Storm_Names = []\n",
    "    for i in range(len(Codes)):\n",
    "        Name = Name_List[int(i%len(Name_List))]\n",
    "        Storm_Names.append(Name)\n",
    "    Codes[\"Name\"] = Storm_Names\n",
    "    DF_Names = []\n",
    "    for k in range(len(DF)):\n",
    "        Code = DF[\"Code\"][k]\n",
    "        Name = list(Codes[Codes[\"New Code\"] == Code][\"Name\"])[0]\n",
    "        DF_Names.append(Name)\n",
    "    DF.insert(1, \"Name\", DF_Names)\n",
    "    return (Codes, DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5525e4-0d83-4040-a886-45c94b9af0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Find Distance Between Two Points\n",
    "def Find_Distance(y1, y2, x1, x2):\n",
    "    Start_Lat = y1 * numpy.pi / 180\n",
    "    End_Lat = y2 * numpy.pi / 180\n",
    "    Start_Lon = x1 * numpy.pi / 180\n",
    "    End_Lon = x2 * numpy.pi / 180\n",
    "    Lat_Diff = End_Lat - Start_Lat\n",
    "    Lon_Diff = End_Lon - Start_Lon\n",
    "    Earth_Rad = 6378\n",
    "    Distance = 2 * Earth_Rad * numpy.sqrt((numpy.sin(Lat_Diff/2))**2 + \\\n",
    "    numpy.cos(Start_Lat) * numpy.cos(End_Lat) * (numpy.sin(Lon_Diff/2))**2)\n",
    "    return (Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0212d175-728c-4e64-a65f-c865e63d48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a Specific Storm Within the DataFrame\n",
    "def Find_Storm(DF, Code):\n",
    "    DF_Storm = DF[DF[\"Code\"] == Code].reset_index()\n",
    "    return (DF_Storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cfee4-5db0-4933-ac51-40f87c3c90b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f34919-cd0a-4068-b189-fdfe53139b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6290456-0efe-47ca-aef4-ab83ad6d1e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d29aac5-9852-467b-bbd3-c9ec7227ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Name List\n",
    "Name_List = Open_Name_List('Storm_Tracking/Storm_Name_List.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc2a90ef-525c-498c-acb7-f8b0b7426fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Functions to Open Datasets\n",
    "Control_A_Data_V0, Control_A_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.control.002_avg')\n",
    "Control_B_Data_V0, Control_B_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.control.003_avg')\n",
    "Control_C_Data_V0, Control_C_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.control_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd59402f-72c9-4bff-aeb4-c0b9b7fc423c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process Control DataFrames\n",
    "Control_Data_V1, Control_Codes_V1, Control_Year_Diffs = \\\n",
    "Combine_DF(Control_A_Data_V0, Control_B_Data_V0, Control_C_Data_V0, \\\n",
    "Control_A_Storm_List_V0, Control_B_Storm_List_V0, Control_C_Storm_List_V0, \"Control\")\n",
    "Control_Codes_V2, Control_Data_V2 = Assign_Name(Name_List, Control_Codes_V1, Control_Data_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eff17ac-313d-402c-aecd-ececbeb4a27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Functions to Open Datasets\n",
    "RCP45_A_Data_V0, RCP45_A_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp45_avg')\n",
    "RCP45_B_Data_V0, RCP45_B_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp45.002_avg')\n",
    "RCP45_C_Data_V0, RCP45_C_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp45.003_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5db523-571a-4e51-9046-46dc662e2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process RCP4.5 DataFrames\n",
    "RCP45_Data_V1, RCP45_Codes_V1, RCP45_Year_Diffs = \\\n",
    "Combine_DF(RCP45_A_Data_V0, RCP45_B_Data_V0, RCP45_C_Data_V0, \\\n",
    "RCP45_A_Storm_List_V0, RCP45_B_Storm_List_V0, RCP45_C_Storm_List_V0, \"RCP45\")\n",
    "RCP45_Codes_V2, RCP45_Data_V2 = Assign_Name(Name_List, RCP45_Codes_V1, RCP45_Data_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6714b9-de29-44db-abc8-fa9be43800ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Functions to Open Datasets\n",
    "RCP85_A_Data_V0, RCP85_A_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp85_avg')\n",
    "RCP85_B_Data_V0, RCP85_B_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp85.003_avg')\n",
    "RCP85_C_Data_V0, RCP85_C_Storm_List_V0 = Create_DF(Diri + 'traj_et_dtime900.rcp85.004_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ecc77c-46b5-4230-9f67-9dd57cc6edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process RCP8.5 DataFrames\n",
    "RCP85_Data_V1, RCP85_Codes_V1, RCP85_Year_Diffs = \\\n",
    "Combine_DF(RCP85_A_Data_V0, RCP85_B_Data_V0, RCP85_C_Data_V0, \\\n",
    "RCP85_A_Storm_List_V0, RCP85_B_Storm_List_V0, RCP85_C_Storm_List_V0, \"RCP85\")\n",
    "RCP85_Codes_V2, RCP85_Data_V2 = Assign_Name(Name_List, RCP85_Codes_V1, RCP85_Data_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb0b2a-f28a-4eab-b9b0-484549faedca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa97e57-fd0d-49a8-9aa6-af2d08a4e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check For Repeated Entries\n",
    "def Repeated_Check(DF):\n",
    "    for i in range(len(DF)):\n",
    "        Lat = DF[\"Lat\"][i]\n",
    "        Lon = DF[\"Lon\"][i]\n",
    "        Time = DF[\"Time(Z)\"][i]\n",
    "        DF_Repeat = DF[(DF[\"Lat\"] == Lat) & (DF[\"Lon\"] == Lon) & (DF[\"Time(Z)\"] == Time)]\n",
    "# Deleted Repeated Entries\n",
    "        if len(DF_Repeat) > 1:\n",
    "            print (DF[\"Code\"][i], Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99539e91-3d45-449d-8f75-67dd3cac489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repeated_Check(Control_Data_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157a51b-0c70-487c-8731-bfbbaf87be27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc126d2-d56a-45c2-a9eb-625a130cfa24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdb66d-2a5f-404a-be3c-57384281909e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d665b702-46ff-4fa7-9d3a-40f108a2b38d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function For Check For Time Discontinuity\n",
    "def Time_Discontinuity(DF_Storm):\n",
    "    Time_Continuous = 0\n",
    "    for k in range(len(DF_Storm)):\n",
    "        if k > 0 and Time_Continuous == 0:\n",
    "#            print (k)\n",
    "# If Over 24 Hours of Missing Data\n",
    "            if DF_Storm[\"Time(Z)\"][k] - DF_Storm[\"Time(Z)\"][k-1] >= datetime.timedelta(hours=24):\n",
    "# Divide Array Into Before The Time Discontinuity and After It\n",
    "                Before = DF_Storm[\"Time(Z)\"][k-1]\n",
    "                After = DF_Storm[\"Time(Z)\"][k]\n",
    "                DF_Before = DF_Storm[DF_Storm[\"Time(Z)\"] <= Before].reset_index()\n",
    "                DF_After = DF_Storm[DF_Storm[\"Time(Z)\"] >= After].reset_index()\n",
    "# Choose the Part with the Lowest Min SLP to Keep\n",
    "                if numpy.min(DF_After[\"SLP(hPa)\"]) <= numpy.min(DF_Before[\"SLP(hPa)\"]) and \\\n",
    "                len(DF_After) > len(DF_Before):\n",
    "                    DF_Storm_Updated = DF_After\n",
    "                else:\n",
    "                    DF_Storm_Updated = DF_Before\n",
    "                Time_Continuous = 1\n",
    "                DF_Storm_Updated = DF_Storm_Updated.drop(\"level_0\", axis=1)\n",
    "# Repeat Until No More Time Discontinuity\n",
    "    if Time_Continuous == 0:\n",
    "        DF_Storm_Updated = DF_Storm.copy()\n",
    "    return (DF_Storm_Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "771b22cb-1f9a-461c-a7a2-fec0cda7c2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function For Check For Track Discontinuity\n",
    "def Track_Discontinuity(DF_Storm):\n",
    "    Track_Continuous = 0\n",
    "    Track_Discon = []\n",
    "    for k in range(len(DF_Storm)):\n",
    "        if k > 1 and Track_Continuous == 0:\n",
    "# Calculate Distance Between Each 6 Hour Interval\n",
    "            Distance_1 = Find_Distance(DF_Storm[\"Lat\"][k], DF_Storm[\"Lat\"][k-1], \\\n",
    "            DF_Storm[\"Lon\"][k], DF_Storm[\"Lon\"][k-1])\n",
    "            Distance_2 = Find_Distance(DF_Storm[\"Lat\"][k-1], DF_Storm[\"Lat\"][k-2], \\\n",
    "            DF_Storm[\"Lon\"][k-1], DF_Storm[\"Lon\"][k-2])\n",
    "# If Distance >= 800km and Distance Over 5 Times Further Than Previous Time Interval\n",
    "            if Distance_1 >= 800 and Distance_1 >= Distance_2 * 5:\n",
    "                Track_Discon = [DF_Storm[\"Code\"][0], DF_Storm[\"Time(Z)\"][k]]\n",
    "# Divide Array Into Before The Track Discontinuity and After It\n",
    "                Before = DF_Storm[\"Time(Z)\"][k-1]\n",
    "                After = DF_Storm[\"Time(Z)\"][k]\n",
    "                DF_Before = DF_Storm[DF_Storm[\"Time(Z)\"] <= Before].reset_index()\n",
    "                DF_After = DF_Storm[DF_Storm[\"Time(Z)\"] >= After].reset_index()\n",
    "# Choose the Part with the Lowest Min SLP to Keep\n",
    "                if numpy.min(DF_After[\"SLP(hPa)\"]) <= numpy.min(DF_Before[\"SLP(hPa)\"]) and \\\n",
    "                len(DF_After) > len(DF_Before):\n",
    "                    DF_Storm_Updated = DF_After\n",
    "                else:\n",
    "                    DF_Storm_Updated = DF_Before\n",
    "                Track_Continuous = 1\n",
    "                DF_Storm_Updated = DF_Storm_Updated.drop(\"level_0\", axis=1)\n",
    "# Repeat Until No More Track Discontinuity\n",
    "    if Track_Continuous == 0:\n",
    "        DF_Storm_Updated = DF_Storm.copy()\n",
    "    return (DF_Storm_Updated, Track_Discon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f55ef42-6366-4c0e-9b47-813ae0fff99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Storms That Have Time Discontinuity or Track Discontinuity\n",
    "def DF_Fixing(DF_Storm_Orig, Track_Discons):\n",
    "    Bottom_Right = False\n",
    "    Top_Right = False\n",
    "    Bottom_Left = False\n",
    "    Top_Left = False\n",
    "    ET_Complete = False\n",
    "#\n",
    "# Check For Time Discontinuity\n",
    "    DF_Storm = Time_Discontinuity(DF_Storm_Orig)\n",
    "# Repeat to Check Again\n",
    "    DF_Storm = Time_Discontinuity(DF_Storm)\n",
    "    DF_Storm = Time_Discontinuity(DF_Storm)\n",
    "#\n",
    "# Check For Track Discontinuity\n",
    "    DF_Storm, Track_Discon = Track_Discontinuity(DF_Storm)\n",
    "    if len(Track_Discon) > 0:\n",
    "        Track_Discons.append(Track_Discon)\n",
    "# Repeat to Check Again\n",
    "    DF_Storm, Track_Discon = Track_Discontinuity(DF_Storm)\n",
    "    if len(Track_Discon) > 0:\n",
    "        Track_Discons.append(Track_Discon)\n",
    "    DF_Storm, Track_Discon = Track_Discontinuity(DF_Storm)\n",
    "    if len(Track_Discon) > 0:\n",
    "        Track_Discons.append(Track_Discon)\n",
    "    return (DF_Storm, Track_Discons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3751f15-cf12-4557-999c-3741efee7be2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Determine Whether a Storm Has Completed ET, and Find Begin and Complete Time of ET\n",
    "def ET_Function(DF_Storm):\n",
    "    Tropical_Begin = False\n",
    "    ET_Begin = False\n",
    "    ET_Complete = False\n",
    "    Bottom_Right_t, Top_Right_t, Bottom_Left_t = [], [], []\n",
    "    ET_Begin_t, ET_Compl_t, Trans_Type = -728, -728, -728\n",
    "    for t in range(len(DF_Storm)):\n",
    "        if ET_Complete == False:\n",
    "            if Tropical_Begin == False:\n",
    "# Storm Must First Be Tropical\n",
    "                if DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "                    Tropical_Begin = True\n",
    "                    Bottom_Right_t.append(t)\n",
    "            if Tropical_Begin == True:\n",
    "# Storm Must Be Tropical For At Least 48 Hours\n",
    "                if len(Bottom_Right_t) <= 8:\n",
    "                    if DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "                        Bottom_Right_t.append(t)\n",
    "#\n",
    "# Enter Next Stage If Storm Remains Tropical For At Least 48 Hours\n",
    "                else:\n",
    "                    if ET_Begin == False:\n",
    "# If Storm Enters Top Right Quadrant = ET Begin\n",
    "                        if DF_Storm[\"B\"][t] > 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "                            ET_Begin = True\n",
    "                            ET_Begin_t = t\n",
    "                            Top_Right_t.append(t)\n",
    "# If Storm Enters Bottom Left Quadrant = ET Begin\n",
    "                        elif DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] < 0:\n",
    "                            ET_Begin = True\n",
    "                            ET_Begin_t = t\n",
    "                            Bottom_Left_t.append(t)\n",
    "# If Storm Directly Enters Top Left Quadrant = ET Complete\n",
    "                        elif DF_Storm[\"B\"][t] > 15 and DF_Storm[\"VLT\"][t] < 0:\n",
    "                            ET_Complete = True\n",
    "                            ET_Begin_t, ET_Compl_t = t, t\n",
    "                            Trans_Type = 3\n",
    "#\n",
    "# After ET Initiation\n",
    "                    elif ET_Begin == True:\n",
    "                        if len(Top_Right_t) > 0 and len(Top_Right_t) >= len(Bottom_Left_t):\n",
    "# If Storm Remains in Top Right Quadrant\n",
    "                            if DF_Storm[\"B\"][t] > 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "                                Top_Right_t.append(t)\n",
    "# If Storm Enters Top Left Quadrant = ET Complete\n",
    "                            elif DF_Storm[\"VLT\"][t] < 0:\n",
    "                                if DF_Storm[\"B\"][t] > 10:\n",
    "                                    ET_Complete = True\n",
    "                                    ET_Compl_t, Trans_Type = t, 1\n",
    "# If Storm Enters Bottom Left Quadrant\n",
    "                                else:\n",
    "                                    Bottom_Left_t.append(t)\n",
    "                            elif DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "# If Storm Returns to Bottom Right Quadrant For Over 24 Hours\n",
    "                                if t-4 > Top_Right_t[len(Top_Right_t)-1]:\n",
    "                                    ET_Begin = False\n",
    "                                    Top_Right_t = []\n",
    "                        elif len(Bottom_Left_t) > 0:\n",
    "# If Storm Remains in Bottom Left Quadrant\n",
    "                            if DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] < 0:\n",
    "                                Bottom_Left_t.append(t)\n",
    "# If Storm Enters Top Left Quadrant = ET Complete\n",
    "                            elif DF_Storm[\"B\"][t] > 15:\n",
    "                                if DF_Storm[\"VLT\"][t] <= 0:\n",
    "                                    ET_Complete = True\n",
    "                                    ET_Compl_t, Trans_Type = t, 2\n",
    "# If Storm Enters Top Right Quadrant\n",
    "                                else:\n",
    "                                    Top_Right_t.append(t)\n",
    "                            elif DF_Storm[\"B\"][t] <= 15 and DF_Storm[\"VLT\"][t] >= 0:\n",
    "# If Storm Returns to Bottom Right Quadrant For Over 24 Hours\n",
    "                                if t-4 > Bottom_Left_t[len(Bottom_Left_t)-1]:\n",
    "                                    ET_Begin = False\n",
    "                                    Bottom_Left_t = []\n",
    "#\n",
    "# If Storm Did Not Spend At Least 48 Hours as Tropical\n",
    "    if len(Bottom_Right_t) <= 8:\n",
    "        Trans_Type = -728\n",
    "# If ET Never Begun:\n",
    "    elif ET_Compl_t == -728:\n",
    "        if ET_Begin_t == -728:\n",
    "            Trans_Type = -1\n",
    "# If ET Began But Did Not Complete:\n",
    "        else:\n",
    "            Trans_Type = 0\n",
    "    return (Trans_Type, ET_Begin_t, ET_Compl_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "900f1324-263d-4739-81c3-0f9d0848da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF With Extratropical Transition Information of Each Storm\n",
    "def Storm_Info_DF(DF, Codes):\n",
    "    ABC = []\n",
    "    Trans_Types, Begin_Times, Compl_Times, Track_Discons = [], [], [], []\n",
    "    for i in range(len(Codes)):\n",
    "        DF_Storm_Orig = DF[DF[\"Code\"] == Codes[\"New Code\"][i]].reset_index()\n",
    "# Apply Functions\n",
    "        DF_Storm, Track_Discons = DF_Fixing(DF_Storm_Orig, Track_Discons)\n",
    "        Trans_Type, ET_Begin_t, ET_Compl_t = ET_Function(DF_Storm)\n",
    "        if ET_Begin_t > 0:\n",
    "            Begin_Time = DF_Storm[\"Time(Z)\"][ET_Begin_t]\n",
    "        else:\n",
    "            Begin_Time = numpy.nan\n",
    "        if ET_Compl_t > 0:\n",
    "            Compl_Time = DF_Storm[\"Time(Z)\"][ET_Compl_t]\n",
    "        else:\n",
    "            Compl_Time = numpy.nan\n",
    "        Begin_Times.append(Begin_Time)\n",
    "        Compl_Times.append(Compl_Time)\n",
    "        Trans_Types.append(Trans_Type)\n",
    "        ABC.append(Codes[\"ABC\"][i])\n",
    "        if i == 0:\n",
    "            DF_Fixed = DF_Storm.copy()\n",
    "        else:\n",
    "            DF_Fixed = pandas.concat([DF_Fixed, DF_Storm])\n",
    "    DF_Fixed = DF_Fixed.reset_index()\n",
    "    DF_Fixed = DF_Fixed.drop(\"index\", axis=1)\n",
    "#\n",
    "# Create Storms DF\n",
    "    Storms_DF_Orig = pandas.DataFrame({\"Code\": Codes[\"New Code\"], \"Name\": Codes[\"Name\"], \\\n",
    "    \"ABC\": ABC, \"Trans Type\": Trans_Types, \"ET Begin Time\": Begin_Times, \"ET Complete Time\": Compl_Times})\n",
    "    return (DF_Fixed, Storms_DF_Orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f05d7305-6f78-4426-a8e1-a629f6fa6980",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Function For Control DataFrames\n",
    "Control_Data_V3, Control_ET_V1 = Storm_Info_DF(Control_Data_V2, Control_Codes_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32650d67-0ced-4ff7-ab90-0580683fb7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Function For RCP4.5 DataFrames\n",
    "RCP45_Data_V3, RCP45_ET_V1 = Storm_Info_DF(RCP45_Data_V2, RCP45_Codes_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91f0702e-7294-4d3f-aeb0-27ffbfa4d775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Function For RCP8.5 DataFrames\n",
    "RCP85_Data_V3, RCP85_ET_V1 = Storm_Info_DF(RCP85_Data_V2, RCP85_Codes_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cd97e-7660-4204-9464-2c73f9893c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2517ece-262e-47bb-a8b8-b10c4eedfc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3757a27-346a-4d0e-a11d-d78e28581cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "862f3141-24de-4b3b-9089-633cd38c87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Storm Phase into DataFrame\n",
    "def Storm_Phase_Info(Data_DF_Orig, ET_DF):\n",
    "    Data_DF = Data_DF_Orig.copy()\n",
    "    Storm_Phase_List = []\n",
    "    for i in range(len(ET_DF)):\n",
    "        DF_Storm = Data_DF[Data_DF[\"Code\"] == ET_DF[\"Code\"][i]].reset_index()\n",
    "        Trans_Type, Begin_Time, Compl_Time = ET_DF[\"Trans Type\"][i], ET_DF[\"ET Begin Time\"][i], ET_DF[\"ET Complete Time\"][i]\n",
    "# Find Storm Phase Based on ET Begin Time and ET Complete Time\n",
    "        Storm_Phase = Find_Storm_Phase(DF_Storm, Begin_Time, Compl_Time, Trans_Type)\n",
    "        for j in range(len(Storm_Phase)):\n",
    "            Storm_Phase_List.append(Storm_Phase[j])\n",
    "    Data_DF[\"Storm Phase\"] = Storm_Phase_List\n",
    "    Data_DF = Data_DF.drop(\"level_0\", axis=1)\n",
    "    return (Data_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec3666ff-3b7a-427c-806e-6f051d11a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Find Storm Phase\n",
    "def Find_Storm_Phase(DF_Storm, Begin_Time, Compl_Time, Trans_Type):\n",
    "    Time = list(DF_Storm[\"Time(Z)\"])\n",
    "    Storm_Phase = []\n",
    "    for k in range(len(DF_Storm)):\n",
    "# If Before ET Begin = Tropical\n",
    "# If Between ET Begin and ET Complete = Transitioning\n",
    "# If After ET Complete = Extratropical\n",
    "        if Trans_Type <= -1:\n",
    "            Storm_Phase.append(\"Tropical\")\n",
    "        elif Trans_Type == 0:\n",
    "            if Time[k] < Begin_Time:\n",
    "                Storm_Phase.append(\"Tropical\")\n",
    "            else:\n",
    "                Storm_Phase.append(\"Transition\")\n",
    "        else:\n",
    "            if Time[k] < Begin_Time:\n",
    "                Storm_Phase.append(\"Tropical\")\n",
    "            elif Time[k] < Compl_Time:\n",
    "                Storm_Phase.append(\"Transition\")\n",
    "            else:\n",
    "                Storm_Phase.append(\"Extratropical\")\n",
    "    return (Storm_Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d666218-178d-44b8-b765-e0cd26584fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V4 = Storm_Phase_Info(Control_Data_V3, Control_ET_V1)\n",
    "RCP45_Data_V4 = Storm_Phase_Info(RCP45_Data_V3, RCP45_ET_V1)\n",
    "RCP85_Data_V4 = Storm_Phase_Info(RCP85_Data_V3, RCP85_ET_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af99d1-3635-4717-a522-f7631925ff11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0681f9c-b8c6-415f-a0eb-61491d1aed04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3d7e195-b23e-4e9d-9007-0c57f7a163cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Lat, Lon, SLP Into ET DataFrame\n",
    "def ET_Variables(Main_DF, ET_DF_Orig):\n",
    "    ET_DF = ET_DF_Orig.copy()\n",
    "    Array = numpy.zeros((15, len(ET_DF)))\n",
    "    Trop_Peak_Times = []\n",
    "    Peak_Times = []\n",
    "    Genesis_Times = []\n",
    "    for i in range(len(ET_DF)):\n",
    "        Code = ET_DF[\"Code\"][i]\n",
    "        Trans_Type, Begin_Time, Compl_Time = ET_DF[\"Trans Type\"][i], ET_DF[\"ET Begin Time\"][i], ET_DF[\"ET Complete Time\"][i]\n",
    "        Storm = Main_DF[Main_DF[\"Code\"] == Code].reset_index()\n",
    "#\n",
    "# Find Lat, Lon, Time at Storm Peak\n",
    "        Min_SLP = numpy.min(Storm[\"SLP(hPa)\"])\n",
    "        Storm_Peak = Storm[Storm[\"SLP(hPa)\"] == Min_SLP]\n",
    "        Array[0][i] = Min_SLP\n",
    "        Array[1][i] = float(Storm_Peak[\"Lon\"].iloc[0])\n",
    "        Array[2][i] = float(Storm_Peak[\"Lat\"].iloc[0])\n",
    "        Peak_Time = Storm_Peak[\"Time(Z)\"].iloc[0]\n",
    "        Peak_Times.append(Peak_Time)\n",
    "#\n",
    "# Find Lat, Lon, Time at Tropical Phase Peak\n",
    "        Storm_Trop = Storm[Storm[\"Storm Phase\"] == \"Tropical\"]\n",
    "        Trop_Min_SLP = numpy.min(Storm_Trop[\"SLP(hPa)\"])\n",
    "        Trop_Peak = Storm[Storm[\"SLP(hPa)\"] == Trop_Min_SLP]\n",
    "        Array[3][i] = Trop_Min_SLP\n",
    "        Array[4][i] = float(Trop_Peak[\"Lon\"].iloc[0])\n",
    "        Array[5][i] = float(Trop_Peak[\"Lat\"].iloc[0])\n",
    "        Trop_Peak_Time = Trop_Peak[\"Time(Z)\"].iloc[0]\n",
    "        Trop_Peak_Times.append(Trop_Peak_Time)\n",
    "#\n",
    "# Find SLP, Lon, Lat at ET Begin\n",
    "        if Trans_Type > -1:\n",
    "            Begin = Storm[Storm[\"Time(Z)\"] == Begin_Time]\n",
    "            Array[6][i] = float(Begin[\"SLP(hPa)\"].iloc[0])\n",
    "            Array[7][i] = float(Begin[\"Lon\"].iloc[0])\n",
    "            Array[8][i] = float(Begin[\"Lat\"].iloc[0])\n",
    "        else:\n",
    "            Array[6][i], Array[7][i], Array[8][i] = numpy.nan, numpy.nan, numpy.nan\n",
    "#\n",
    "# Find SLP, Lon, Lat at ET Complete\n",
    "        if Trans_Type > 0:\n",
    "            Complete = Storm[Storm[\"Time(Z)\"] == Compl_Time]\n",
    "            Array[9][i] = float(Complete[\"SLP(hPa)\"].iloc[0])\n",
    "            Array[10][i] = float(Complete[\"Lon\"].iloc[0])\n",
    "            Array[11][i] = float(Complete[\"Lat\"].iloc[0])\n",
    "        else:\n",
    "            Array[9][i], Array[10][i], Array[11][i] = numpy.nan, numpy.nan, numpy.nan\n",
    "#\n",
    "# Find SLP, Lon, Lat at Genesis\n",
    "        Genesis_Time = Storm[\"Time(Z)\"].iloc[1]\n",
    "        Genesis_Times.append(Genesis_Time)\n",
    "        Array[12][i] = float(Storm[\"SLP(hPa)\"].iloc[1])\n",
    "        Array[13][i] = float(Storm[\"Lon\"].iloc[1])\n",
    "        Array[14][i] = float(Storm[\"Lat\"].iloc[1])\n",
    "#\n",
    "# Append Into ET DF\n",
    "    ET_DF[\"Peak Time\"] = Peak_Times\n",
    "    ET_DF[\"Trop Peak Time\"] = Trop_Peak_Times\n",
    "    ET_DF[\"Genesis Time\"] = Genesis_Times\n",
    "    ET_DF[\"Peak SLP\"] = Array[0]\n",
    "    ET_DF[\"Peak Lon\"] = Array[1]\n",
    "    ET_DF[\"Peak Lat\"] = Array[2]\n",
    "    ET_DF[\"Trop Peak SLP\"] = Array[3]\n",
    "    ET_DF[\"Trop Peak Lon\"] = Array[4]\n",
    "    ET_DF[\"Trop Peak Lat\"] = Array[5]\n",
    "    ET_DF[\"ET Begin SLP\"] = Array[6]\n",
    "    ET_DF[\"ET Begin Lon\"] = Array[7]\n",
    "    ET_DF[\"ET Begin Lat\"] = Array[8]\n",
    "    ET_DF[\"ET Complete SLP\"] = Array[9]\n",
    "    ET_DF[\"ET Complete Lon\"] = Array[10]\n",
    "    ET_DF[\"ET Complete Lat\"] = Array[11]\n",
    "    ET_DF[\"Genesis SLP\"] = Array[12]\n",
    "    ET_DF[\"Genesis Lon\"] = Array[13]\n",
    "    ET_DF[\"Genesis Lat\"] = Array[14]\n",
    "    return (ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23c0ed4-ab64-42d8-88b6-df76f93a83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_ET_V2 = ET_Variables(Control_Data_V4, Control_ET_V1)\n",
    "RCP45_ET_V2 = ET_Variables(RCP45_Data_V4, RCP45_ET_V1)\n",
    "RCP85_ET_V2 = ET_Variables(RCP85_Data_V4, RCP85_ET_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "735309eb-bf5c-4280-a46a-4b5d314f15db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954 748 654\n"
     ]
    }
   ],
   "source": [
    "# Raw Dataset\n",
    "print (len(Control_ET_V2), len(RCP45_ET_V2), len(RCP85_ET_V2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56fe80-86a8-4434-b2e8-bd0183a360ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02ff6f-ff8e-465a-b616-838954f71e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725aa1b0-daac-42f1-a4c1-bc3f1e4af43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "715e60f9-2c70-423d-8ce5-c584a4582d18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter Out Storms That Have Not Been Tropical For At Least 48 Hours\n",
    "def Tropical_Filter(Data_DF_Orig, ET_DF_Orig, Codes_DF_Orig):\n",
    "    Filtered_ET_0 = ET_DF_Orig[ET_DF_Orig[\"Trans Type\"] > -728].reset_index().drop(\"index\", axis=1)\n",
    "# Filter Out Storms With Peak SLP >= 1000hPa\n",
    "    Filtered_ET = Filtered_ET_0[Filtered_ET_0[\"Peak SLP\"] < 1000].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = Filtered_ET[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    Filtered_Codes = Codes_DF_Orig[Codes_DF_Orig[\"New Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    return (Filtered_DF, Filtered_ET, Filtered_Codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b1966b-9210-4971-a86f-63b96012b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V5, Control_ET_V5, Control_Codes_V5 = Tropical_Filter(Control_Data_V4, Control_ET_V2, Control_Codes_V2)\n",
    "RCP45_Data_V5, RCP45_ET_V5, RCP45_Codes_V5 = Tropical_Filter(RCP45_Data_V4, RCP45_ET_V2, RCP45_Codes_V2)\n",
    "RCP85_Data_V5, RCP85_ET_V5, RCP85_Codes_V5 = Tropical_Filter(RCP85_Data_V4, RCP85_ET_V2, RCP85_Codes_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bec582-cf3d-49ae-b8a4-77d299718ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649 460 407\n"
     ]
    }
   ],
   "source": [
    "# Dataset A\n",
    "print (len(Control_ET_V5), len(RCP45_ET_V5), len(RCP85_ET_V5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11667056-8b73-48aa-ab1d-ce1629a4d08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8407ba1-3296-48fb-a532-f4c2079ec632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be27ed-8cd5-4d76-bf9e-3bb5914ec731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ffa22a-6872-49c5-a3c5-9554b9105ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Transition Type\n",
    "Control_ET_Count = numpy.zeros(3)\n",
    "RCP45_ET_Count = numpy.zeros(3)\n",
    "RCP85_ET_Count = numpy.zeros(3)\n",
    "Control_ET_Count[0] = len(Control_ET_V5[Control_ET_V5[\"Trans Type\"] <= -1])\n",
    "Control_ET_Count[1] = len(Control_ET_V5[Control_ET_V5[\"Trans Type\"] == 0])\n",
    "Control_ET_Count[2] = len(Control_ET_V5[Control_ET_V5[\"Trans Type\"] >= 1])\n",
    "RCP45_ET_Count[0] = len(RCP45_ET_V5[RCP45_ET_V5[\"Trans Type\"] <= -1])\n",
    "RCP45_ET_Count[1] = len(RCP45_ET_V5[RCP45_ET_V5[\"Trans Type\"] == 0])\n",
    "RCP45_ET_Count[2] = len(RCP45_ET_V5[RCP45_ET_V5[\"Trans Type\"] >= 1])\n",
    "RCP85_ET_Count[0] = len(RCP85_ET_V5[RCP85_ET_V5[\"Trans Type\"] <= -1])\n",
    "RCP85_ET_Count[1] = len(RCP85_ET_V5[RCP85_ET_V5[\"Trans Type\"] == 0])\n",
    "RCP85_ET_Count[2] = len(RCP85_ET_V5[RCP85_ET_V5[\"Trans Type\"] >= 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fc3895a-5c4d-4602-bb8b-d8c2d86c4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20801233 0.35747304 0.43451464]\n",
      "[0.22173913 0.36521739 0.41304348]\n",
      "[0.19410319 0.31941032 0.48648649]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Percentages of ET Completion\n",
    "Control_ET_Percents = Control_ET_Count / len(Control_ET_V5)\n",
    "RCP45_ET_Percents = RCP45_ET_Count / len(RCP45_ET_V5)\n",
    "RCP85_ET_Percents = RCP85_ET_Count / len(RCP85_ET_V5)\n",
    "print (Control_ET_Percents)\n",
    "print (RCP45_ET_Percents)\n",
    "print (RCP85_ET_Percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c2847cd-6915-4f32-a02f-c24a32ad0326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trans Type</th>\n",
       "      <th>Control</th>\n",
       "      <th>RCP4.5</th>\n",
       "      <th>RCP8.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No ET</td>\n",
       "      <td>0.208012</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.194103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ET Incomplete</td>\n",
       "      <td>0.357473</td>\n",
       "      <td>0.365217</td>\n",
       "      <td>0.319410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ET Complete</td>\n",
       "      <td>0.434515</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Trans Type   Control    RCP4.5    RCP8.5\n",
       "0          No ET  0.208012  0.221739  0.194103\n",
       "1  ET Incomplete  0.357473  0.365217  0.319410\n",
       "2    ET Complete  0.434515  0.413043  0.486486"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Percentages of ET Completion\n",
    "ET_Percents = pandas.DataFrame({\"Trans Type\": [\"No ET\", \"ET Incomplete\", \"ET Complete\"], \\\n",
    "\"Control\": Control_ET_Percents, \"RCP4.5\": RCP45_ET_Percents, \"RCP8.5\": RCP85_ET_Percents})\n",
    "ET_Percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75595edd-5ce4-4fc4-a7c5-06f583430b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb32ff6-6195-4f57-837d-eb10c54eec04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54e064-9623-47aa-be29-d774f29dcf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f80f9d3c-9f66-470c-b980-0af527f6f8f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter For Storms That Completed ET Transition\n",
    "def ET_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "    ET_DF = ET_DF_Orig[ET_DF_Orig[\"Trans Type\"] > 0].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25c215f0-ee34-4538-9542-3b04178103f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V6, Control_ET_V6 = ET_Filter(Control_Data_V5, Control_ET_V5)\n",
    "RCP45_Data_V6, RCP45_ET_V6 = ET_Filter(RCP45_Data_V5, RCP45_ET_V5)\n",
    "RCP85_Data_V6, RCP85_ET_V6 = ET_Filter(RCP85_Data_V5, RCP85_ET_V5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e510a67a-3598-4792-aa19-fd7c8e35222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 190 198\n"
     ]
    }
   ],
   "source": [
    "# Dataset B\n",
    "print (len(Control_ET_V6), len(RCP45_ET_V6), len(RCP85_ET_V6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725b2b5-b80a-43c7-b3cf-7917af2a2297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb6342-16d1-4767-b10f-42259e04e08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f319f5a-a89f-4745-82b2-2f6fa23d642b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df594646-b716-4d0c-ba88-4a239009d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter For Storms With Trop Peak SLP <= 990, ET Begin SLP <= 1008 and ET Complete SLP <= 1008\n",
    "def SLP_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "    ET_DF = ET_DF_Orig[(ET_DF_Orig[\"Trop Peak SLP\"] <= 990) & (ET_DF_Orig[\"ET Begin SLP\"] <= 1008) & \\\n",
    "    (ET_DF_Orig[\"ET Complete SLP\"] <= 1008)].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a508bb2c-5ef1-498e-9230-95a3651a9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V7, Control_ET_V7 = SLP_Filter(Control_Data_V6, Control_ET_V6)\n",
    "RCP45_Data_V7, RCP45_ET_V7 = SLP_Filter(RCP45_Data_V6, RCP45_ET_V6)\n",
    "RCP85_Data_V7, RCP85_ET_V7 = SLP_Filter(RCP85_Data_V6, RCP85_ET_V6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efa345-66ac-4b65-834b-b5d57d50e339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67e0cdd6-8aff-4f1c-b56f-933484e6ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter For Storms Based on ET Location\n",
    "def ET_Loc_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "# Filter Out ETs Near European Coast\n",
    "    ET_DF_Filt = ET_DF_Orig[(ET_DF_Orig[\"ET Complete Lon\"] < -12)]\n",
    "# Filter Out ETs Deep Inland Within North America\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 31) | (ET_DF_Filt[\"ET Begin Lon\"] > -83)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 34) | (ET_DF_Filt[\"ET Begin Lon\"] > -81)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 36) | (ET_DF_Filt[\"ET Begin Lon\"] > -78)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 40) | (ET_DF_Filt[\"ET Begin Lon\"] > -76)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 45) | (ET_DF_Filt[\"ET Begin Lon\"] > -72)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 49) | (ET_DF_Filt[\"ET Begin Lon\"] > -68)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] < 52) | (ET_DF_Filt[\"ET Begin Lon\"] > -62)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 31) | (ET_DF_Filt[\"ET Complete Lon\"] > -83)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 34) | (ET_DF_Filt[\"ET Complete Lon\"] > -81)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 36) | (ET_DF_Filt[\"ET Complete Lon\"] > -78)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 40) | (ET_DF_Filt[\"ET Complete Lon\"] > -76)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 45) | (ET_DF_Filt[\"ET Complete Lon\"] > -72)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 49) | (ET_DF_Filt[\"ET Complete Lon\"] > -68)]\n",
    "    ET_DF_Filt = ET_DF_Filt[(ET_DF_Filt[\"ET Complete Lat\"] < 52) | (ET_DF_Filt[\"ET Complete Lon\"] > -62)]\n",
    "    ET_DF = ET_DF_Filt.reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bd794f1-e51c-44bf-9a5e-7811d669b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V8, Control_ET_V8 = ET_Loc_Filter(Control_Data_V7, Control_ET_V7)\n",
    "RCP45_Data_V8, RCP45_ET_V8 = ET_Loc_Filter(RCP45_Data_V7, RCP45_ET_V7)\n",
    "RCP85_Data_V8, RCP85_ET_V8 = ET_Loc_Filter(RCP85_Data_V7, RCP85_ET_V7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99ed0c-7aa3-49bd-a401-69029024932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d105efda-aa39-45b4-bc2a-aea72cb927dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter For Storms Based on Movement Direction\n",
    "def ET_Direction_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "# Only Storms That Move Northeastward Between ET Begin and ET Complete\n",
    "    ET_DF_Filt = ET_DF_Orig[(ET_DF_Orig[\"ET Begin Lat\"] <= ET_DF_Orig[\"ET Complete Lat\"]) \\\n",
    "    & (ET_DF_Orig[\"ET Begin Lon\"] <= ET_DF_Orig[\"ET Complete Lon\"])]\n",
    "# For Storms Where ET Begin == ET Complete\n",
    "    ET_DF_Unsure = ET_DF_Filt[(ET_DF_Filt[\"ET Begin Lat\"] == ET_DF_Filt[\"ET Complete Lat\"]) \\\n",
    "    & (ET_DF_Filt[\"ET Begin Lon\"] == ET_DF_Filt[\"ET Complete Lon\"])]\n",
    "    Unsure_Codes = list(ET_DF_Unsure[\"Code\"])\n",
    "    Codes_Remove = []\n",
    "# Check If Storm Move Northeastward Between Last Tropical Datapoint and ET Complete\n",
    "    for i in range(len(Unsure_Codes)):\n",
    "        DF_Storm = Find_Storm(Data_DF_Orig, Unsure_Codes[i])\n",
    "        DF_Storm_TC = DF_Storm[DF_Storm[\"Storm Phase\"] == \"Tropical\"].reset_index()\n",
    "        DF_Storm_ExTC = DF_Storm[DF_Storm[\"Storm Phase\"] == \"Extratropical\"].reset_index()\n",
    "        if (DF_Storm_TC[\"Lat\"][len(DF_Storm_TC)-1] > DF_Storm_ExTC[\"Lat\"][0]) or \\\n",
    "        (DF_Storm_TC[\"Lon\"][len(DF_Storm_TC)-1] > DF_Storm_ExTC[\"Lon\"][0]):\n",
    "            Codes_Remove.append(Unsure_Codes[i])\n",
    "# Remove Filtered Out Storms\n",
    "    ET_DF = ET_DF_Filt[~ET_DF_Filt[\"Code\"].isin(Codes_Remove)].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d68f3fcc-b57b-416f-ba9b-e6d28ee8b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V9, Control_ET_V9 = ET_Direction_Filter(Control_Data_V8, Control_ET_V8)\n",
    "RCP45_Data_V9, RCP45_ET_V9 = ET_Direction_Filter(RCP45_Data_V8, RCP45_ET_V8)\n",
    "RCP85_Data_V9, RCP85_ET_V9 = ET_Direction_Filter(RCP85_Data_V8, RCP85_ET_V8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2a2ca-898f-4a2d-978e-453a38f73496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acb1c328-3a9b-4ce6-81c4-07006a62f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter For Storms Based on Phase Space Parameters\n",
    "def Phase_Space_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "    Unsure_Codes = ET_DF_Orig[\"Code\"]\n",
    "    Codes_Remove = []\n",
    "    for i in range(len(Unsure_Codes)):\n",
    "        DF_Storm = Find_Storm(Data_DF_Orig, Unsure_Codes[i])\n",
    "        DF_Storm_TC = DF_Storm[DF_Storm[\"Storm Phase\"] == \"Tropical\"].reset_index()\n",
    "# Remove Storms With Trop Peak Outside Bottom Right Quadrant\n",
    "        Trop_Peak_SLP = numpy.min(DF_Storm_TC[\"SLP(hPa)\"])\n",
    "        for j in range(len(DF_Storm_TC)):\n",
    "            if DF_Storm_TC[\"SLP(hPa)\"][j] == Trop_Peak_SLP:\n",
    "                if (DF_Storm_TC[\"B\"][j] > 15) or (DF_Storm_TC[\"VLT\"][j] < 0):\n",
    "                    if Unsure_Codes[i] not in Codes_Remove:\n",
    "                        Codes_Remove.append(Unsure_Codes[i])\n",
    "# Remove Filtered Out Storms\n",
    "    ET_DF = ET_DF_Orig[~ET_DF_Orig[\"Code\"].isin(Codes_Remove)].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "#    print (Codes_Remove)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "367483d9-4688-494a-883d-4e77867ca4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V10, Control_ET_V10 = Phase_Space_Filter(Control_Data_V9, Control_ET_V9)\n",
    "RCP45_Data_V10, RCP45_ET_V10 = Phase_Space_Filter(RCP45_Data_V9, RCP45_ET_V9)\n",
    "RCP85_Data_V10, RCP85_ET_V10 = Phase_Space_Filter(RCP85_Data_V9, RCP85_ET_V9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755b371-e6dc-4b01-a129-837a14721c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2029a173-ecf1-4ec4-86d4-492f08a79b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter For Storms Based on Tropical Peak SLP and Tropical Duration\n",
    "def Peak_SLP_Filter(Data_DF_Orig, ET_DF_Orig):\n",
    "    Unsure_Codes = list(ET_DF_Orig[\"Code\"])\n",
    "    Codes_Remove = []\n",
    "    for i in range(len(Unsure_Codes)):\n",
    "        DF_Storm = Find_Storm(Data_DF_Orig, Unsure_Codes[i])\n",
    "        DF_Storm_Trop = DF_Storm[DF_Storm[\"Storm Phase\"] == \"Tropical\"].reset_index()\n",
    "# Filter Out Storms With Genesis SLP - Tropical Peak SLP < 10:\n",
    "        if DF_Storm_Trop[\"SLP(hPa)\"][0] - numpy.min(DF_Storm_Trop[\"SLP(hPa)\"]) < 10 and Unsure_Codes[i] not in Codes_Remove:\n",
    "            Codes_Remove.append(Unsure_Codes[i])\n",
    "# Filter Out Storms With Tropical Duration < 72 hours:\n",
    "        elif len(DF_Storm_Trop[\"SLP(hPa)\"]) < 12 and Unsure_Codes[i] not in Codes_Remove:\n",
    "            Codes_Remove.append(Unsure_Codes[i])\n",
    "# Remove Filtered Out Storms\n",
    "    ET_DF = ET_DF_Orig[~ET_DF_Orig[\"Code\"].isin(Codes_Remove)].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "#    print (Codes_Remove)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17581574-6a9e-4fe5-8b96-bfe0a7efdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V11, Control_ET_V11 = Peak_SLP_Filter(Control_Data_V10, Control_ET_V10)\n",
    "RCP45_Data_V11, RCP45_ET_V11 = Peak_SLP_Filter(RCP45_Data_V10, RCP45_ET_V10)\n",
    "RCP85_Data_V11, RCP85_ET_V11 = Peak_SLP_Filter(RCP85_Data_V10, RCP85_ET_V10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933ea2e-71c8-4ed8-95d3-a57c8e19d1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b16280c6-33a9-4dab-a132-f1f6c10cb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes of Storm With Incomplete Composite Data\n",
    "Incomplete_Codes = [\"TC191013\", \"TC191309\", \"TC192010\", \"TC192211\", \"TC192306\", \"TC192904\", \"TC193601\", \"TC194802\", \"TC195107\", \"TC195309\", \"TC195808\", \\\n",
    "\"TC200004\", \"TC201309\", \"TC202406\", \"TC202508\", \"TC202601\", \"TC203303\", \"TC203803\", \"TC204304\", \"TC206201\", \"TC206601\", \"TC207801\", \"TC208806\", \\\n",
    "\"TC210005\", \"TC211501\", \"TC212201\", \"TC213506\", \"TC214601\", \"TC214805\", \"TC215101\", \"TC215702\", \"TC216202\", \"TC216209\", \"TC218204\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e7b2e2f-0b72-45fa-9c32-8274db13ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Out Storms With Incomplete Composite Data\n",
    "def Incomplete_Filter(Data_DF_Orig, ET_DF_Orig, Incomplete_Codes):\n",
    "    Unsure_Codes = list(ET_DF_Orig[\"Code\"])\n",
    "    Codes_Remove = []\n",
    "    for i in range(len(Unsure_Codes)):\n",
    "        if Unsure_Codes[i] in Incomplete_Codes:\n",
    "            Codes_Remove.append(Unsure_Codes[i])\n",
    "    ET_DF = ET_DF_Orig[~ET_DF_Orig[\"Code\"].isin(Codes_Remove)].reset_index().drop(\"index\", axis=1)\n",
    "    Code_List = ET_DF[\"Code\"]\n",
    "    Filtered_DF = Data_DF_Orig[Data_DF_Orig[\"Code\"].isin(Code_List)].reset_index().drop(\"index\", axis=1)\n",
    "#    print (Codes_Remove)\n",
    "    return (Filtered_DF, ET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04ee639b-4a05-4a65-a311-2b583c50633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Function\n",
    "Control_Data_V12, Control_ET_V12 = Incomplete_Filter(Control_Data_V11, Control_ET_V11, Incomplete_Codes)\n",
    "RCP45_Data_V12, RCP45_ET_V12 = Incomplete_Filter(RCP45_Data_V11, RCP45_ET_V11, Incomplete_Codes)\n",
    "RCP85_Data_V12, RCP85_ET_V12 = Incomplete_Filter(RCP85_Data_V11, RCP85_ET_V11, Incomplete_Codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4239770b-e0ca-415a-be3b-62bd22e20c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 48 55\n"
     ]
    }
   ],
   "source": [
    "# Dataset C\n",
    "print (len(Control_ET_V12), len(RCP45_ET_V12), len(RCP85_ET_V12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e806b-dfe8-44ca-aba6-b2d6bbdf5022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460fc1c-8f7e-4233-9a34-c798dd34bb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37b411-72c5-4ed6-bcea-ba48f275df3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9fa18da-a9a4-4f6e-b854-b89ffe5c1f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Control</th>\n",
       "      <th>RCP4.5</th>\n",
       "      <th>RCP8.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw</td>\n",
       "      <td>954</td>\n",
       "      <td>748</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset A</td>\n",
       "      <td>649</td>\n",
       "      <td>460</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subset B</td>\n",
       "      <td>282</td>\n",
       "      <td>190</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subset C</td>\n",
       "      <td>89</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Control  RCP4.5  RCP8.5\n",
       "0        Raw      954     748     654\n",
       "1  Dataset A      649     460     407\n",
       "2   Subset B      282     190     198\n",
       "3   Subset C       89      48      55"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 1\n",
    "# Show Number of Storms In Each Subset\n",
    "Storm_Counts = pandas.DataFrame({\"Dataset\": [\"Raw\", \"Dataset A\", \"Subset B\", \"Subset C\"], \\\n",
    "\"Control\": [len(Control_ET_V2), len(Control_ET_V5), len(Control_ET_V6), len(Control_ET_V12)], \\\n",
    "\"RCP4.5\": [len(RCP45_ET_V2), len(RCP45_ET_V5), len(RCP45_ET_V6), len(RCP45_ET_V12)], \\\n",
    "\"RCP8.5\": [len(RCP85_ET_V2), len(RCP85_ET_V5), len(RCP85_ET_V6), len(RCP85_ET_V12)]})\n",
    "Storm_Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50bb04-0083-4968-a969-deb1fdaacb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb3eda-21f9-4cc2-a36a-0ebf4011978f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f7e9f-f2d1-4d83-b895-8ef1a498ee5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65af8bd2-2836-4710-82d8-1f99641148df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output DF to csv File\n",
    "def Output_File(DF, Model, Type):\n",
    "    File_Name = str(Model+'_'+Type+'_Output.csv')\n",
    "    DF.to_csv(Output_Diri+File_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ae38449-c33a-436a-b21a-b13e53da09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Control Files\n",
    "Output_File(Control_Data_V5, \"Control\", \"Data_DatasetA\")\n",
    "Output_File(Control_Data_V6, \"Control\", \"Data_SubsetB\")\n",
    "Output_File(Control_Data_V12, \"Control\", \"Data_SubsetC\")\n",
    "Output_File(Control_ET_V5, \"Control\", \"ET_DatasetA\")\n",
    "Output_File(Control_ET_V6, \"Control\", \"ET_SubsetB\")\n",
    "Output_File(Control_ET_V12, \"Control\", \"ET_SubsetC\")\n",
    "Output_File(Control_Codes_V5, \"Control\", \"Codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1551b6d-dab1-4ba7-b54e-f1d273c66d9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output RCP4.5 Files\n",
    "Output_File(RCP45_Data_V5, \"RCP45\", \"Data_DatasetA\")\n",
    "Output_File(RCP45_Data_V6, \"RCP45\", \"Data_SubsetB\")\n",
    "Output_File(RCP45_Data_V12, \"RCP45\", \"Data_SubsetC\")\n",
    "Output_File(RCP45_ET_V5, \"RCP45\", \"ET_DatasetA\")\n",
    "Output_File(RCP45_ET_V6, \"RCP45\", \"ET_SubsetB\")\n",
    "Output_File(RCP45_ET_V12, \"RCP45\", \"ET_SubsetC\")\n",
    "Output_File(RCP45_Codes_V5, \"RCP45\", \"Codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99b2c29d-3df8-4202-a77d-62e703af9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output RCP8.5 Files\n",
    "Output_File(RCP85_Data_V5, \"RCP85\", \"Data_DatasetA\")\n",
    "Output_File(RCP85_Data_V6, \"RCP85\", \"Data_SubsetB\")\n",
    "Output_File(RCP85_Data_V12, \"RCP85\", \"Data_SubsetC\")\n",
    "Output_File(RCP85_ET_V5, \"RCP85\", \"ET_DatasetA\")\n",
    "Output_File(RCP85_ET_V6, \"RCP85\", \"ET_SubsetB\")\n",
    "Output_File(RCP85_ET_V12, \"RCP85\", \"ET_SubsetC\")\n",
    "Output_File(RCP85_Codes_V5, \"RCP85\", \"Codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41060b26-018f-498c-81c3-718a5f2e6eba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063070b-6082-4712-97cd-d7251ef55ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
